{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SA_VSM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Build Sentiment Dictionaries from VSMs\n",
        "\n",
        "This script allows you to create your own Sentiment Dictionary using Vector Space Models"
      ],
      "metadata": {
        "id": "RFe3xDyK6px1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.Preparation**\n",
        "\n",
        "Download the model.  \n",
        "You can select any model from here: https://fasttext.cc/docs/en/crawl-vectors.html"
      ],
      "metadata": {
        "id": "9wv7zBLw64I_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zfbBGs-35NI5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import gensim\n",
        "import urllib.request\n",
        "import os.path\n",
        "import pandas\n",
        "import numpy as np\n",
        "import scipy.stats as stats"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we download the model\n",
        "#Here we dowload the Spanish model, named \"cc.es.300.vec.gz\"\n",
        "\n",
        "!wget \"https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.vec.gz\"\n",
        "!gunzip cc.es.300.vec.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s4E6zBQ5rb-",
        "outputId": "f99cf195-3bb2-46d6-c34c-b957d63e7e7d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-03 08:50:30--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.es.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.75.142, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1285580896 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.es.300.vec.gz’\n",
            "\n",
            "cc.es.300.vec.gz    100%[===================>]   1.20G  34.1MB/s    in 74s     \n",
            "\n",
            "2022-06-03 08:51:46 (16.5 MB/s) - ‘cc.es.300.vec.gz’ saved [1285580896/1285580896]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Note that \".gz\" is not in the name anymore, as we unzipped the file)\n",
        "\n",
        "filename = 'cc.es.300.vec'\n",
        "\n",
        "my_model = gensim.models.KeyedVectors.load_word2vec_format(filename, binary=False)"
      ],
      "metadata": {
        "id": "nfFntLbU5Srw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.Prepare SA lexicon**\n",
        "\n",
        "Here you need to define the \"seed words\" for the lexicon.  \n",
        "Here we test it with two dimensions, \"happy\" and \"sad\"."
      ],
      "metadata": {
        "id": "mvZBmncz8dL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "happy_labels = ['feliz', 'emocionado', 'positivo', 'alegre'] #I added happy, excited, positive, cheerfull\n",
        "sad_labels = ['triste', 'arrepentido', 'deprimido', 'introvertido'] #I added sad, sorry, depressed, introvert\n",
        "\n",
        "all_words = list(my_model.vocab.keys())"
      ],
      "metadata": {
        "id": "n6Uyw3Dx80Lv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "happy_ordered_words = my_model.most_similar(positive = happy_labels, topn = len(all_words))\n",
        "sad_ordered_words = my_model.most_similar(positive = sad_labels, topn = len(all_words))"
      ],
      "metadata": {
        "id": "S0hEW4UX9N06"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Happy labels\n",
        "happy_words = []\n",
        "happy_value = []\n",
        "\n",
        "for my_tuple in happy_ordered_words:\n",
        "  happy_words.append(my_tuple[0])\n",
        "  happy_value.append(my_tuple[1])\n",
        "\n",
        "#Sad labels\n",
        "sad_words = []\n",
        "sad_value = []\n",
        "\n",
        "for my_tuple in sad_ordered_words:\n",
        "  sad_words.append(my_tuple[0])\n",
        "  sad_value.append(my_tuple[1])\n"
      ],
      "metadata": {
        "id": "iYLHL44X9jO5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Happy values\n",
        "happy_value = np.array(happy_value)\n",
        "happy_value = stats.zscore(happy_value)\n",
        "\n",
        "happy_df = pandas.DataFrame(list(zip(happy_words, happy_value)), \n",
        "               columns =['word', 'happy'])\n",
        "\n",
        "happy_df = happy_df.sort_values('word', ascending=True)\n",
        "\n",
        "\n",
        "#Sad values\n",
        "sad_value = np.array(sad_value)\n",
        "sad_value = stats.zscore(sad_value)\n",
        "\n",
        "sad_df = pandas.DataFrame(list(zip(sad_words, sad_value)), \n",
        "               columns =['word', 'sad'])\n",
        "\n",
        "sad_df = sad_df.sort_values('word', ascending=True)\n",
        "\n",
        "# you can add more categories, if you like..."
      ],
      "metadata": {
        "id": "F-Tm3117-F5g"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Finally, we can save all to unique dataframe\n",
        "sa_df = happy_df.merge(sad_df, how = 'inner', on = ['word'])\n",
        "# sa_df = happy_df.merge(sad_df, fear_df, surprise_df, ..., how = 'inner', on = ['word'])\n",
        "\n",
        "sa_df.to_csv('my_SA_dictionary.csv', index=False)"
      ],
      "metadata": {
        "id": "fJ5eVBSK-tmq"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}